{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN3phen8h8vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe91e8f-6035-4f0b-ad88-b6fd18a13c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsSgTFxXgji_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxpIFHZiiB9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d465e8bb-ae8a-447b-8c05-f992bcfa5842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEE2ul7AjRQH"
      },
      "outputs": [],
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
        "text = text[300000:800000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kTbFeBrjcr1"
      },
      "outputs": [],
      "source": [
        "characters = sorted(set(text))\n",
        "char_to_index = {c: i for i, c in enumerate(characters)}\n",
        "index_to_char = {i: c for i, c in enumerate(characters)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOj0paa5jmTn"
      },
      "outputs": [],
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = [] #features\n",
        "next_characters = [] # targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_dG21QYldfz"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(text) -SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i+SEQ_LENGTH])\n",
        "    next_characters.append(text[i+SEQ_LENGTH])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Quq0J2BOppT"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)))\n",
        "y = np.zeros((len(sentences), len(characters)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmgKL3KanYow"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the input and output sequences\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_to_index[char]] = 1  # One-hot encoding for input\n",
        "    y[i, char_to_index[next_characters[i]]] = 1  # One-hot encoding for output (next character)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiB2foM0OppU",
        "outputId": "c94d5b96-450c-43c0-e99c-366ecfcb57fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))  # LSTM layer with 128 units\n",
        "model.add(Dense(len(characters)))  # Output layer with units equal to the number of characters\n",
        "model.add(Activation('softmax'))  # Softmax activation for multi-class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTCPI2RkOppV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f71952a-bc21-4d85-ffd6-8c75640e019e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 181ms/step - loss: 2.4785\n",
            "Epoch 2/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 178ms/step - loss: 1.7714\n",
            "Epoch 3/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 180ms/step - loss: 1.6119\n",
            "Epoch 4/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 185ms/step - loss: 1.5259\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78a0d25c6470>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temprature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temprature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "vWTJ-ypoScNP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, character in enumerate(sentence):\n",
        "             x[0, t, char_to_index[character]] = 1\n",
        "        predictions = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(predictions, temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "metadata": {
        "id": "DWp_xUbDSaHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('---------0.2-----------')\n",
        "print(generate_text(300, 0.2))\n",
        "print('---------0.4-----------')\n",
        "print(generate_text(300, 0.4))\n",
        "print('---------0.6-----------')\n",
        "print(generate_text(300, 0.6))\n",
        "print('---------0.8-----------')\n",
        "print(generate_text(300, 0.8))\n",
        "print('---------1.0-----------')\n",
        "print(generate_text(300, 1.0))"
      ],
      "metadata": {
        "id": "UBp9G4afWEJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6420fb-efe6-4119-c76f-f9ad33ecdab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------0.2-----------\n",
            "elcome is the stroke of death to me\n",
            "than the heart the grace the heart the grace\n",
            "and the heart of the shall i am the streads,\n",
            "the string the forth the heart of the grief\n",
            "and the come in the heart the heart of the son\n",
            "the forth the heaven the world and men the grace\n",
            "and the the fout the heart with the many and the grace\n",
            "and the tongue the \n",
            "---------0.4-----------\n",
            "hou fortunate!\n",
            "\n",
            "montague:\n",
            "comfort, my lord, and there see the gentlemen\n",
            "shall the world and be sett the days the worther\n",
            "the would be the forth which fortune contence\n",
            "and the more and we come stand the counsers\n",
            "and the tongue the bentle this blood, there streach,\n",
            "and i am my most him to the secr;\n",
            "and my son in the world to the heart and t\n",
            "---------0.6-----------\n",
            "ll her, emilia.\n",
            "i'll use that tongue i hate temple foreft\n",
            "and there is the eyes of the trangent to the sire,\n",
            "but this shall be men the rest fortune and longeed,\n",
            "and num best the crown shall peace to the clarence,\n",
            "by the heaven not you to can my font their fortered\n",
            "that the criems me that death, and lieed\n",
            "who less and is recentle sunder fo\n",
            "---------0.8-----------\n",
            " ransom of my bold attempt\n",
            "shall be this son the life in un woughts\n",
            "the savery take fear for them back and soul,\n",
            "tybalty's come the hereing-tears sank the tranted\n",
            "in god my daughter my sucrion my name him,\n",
            "while he for steel thou liepelf undengeful.\n",
            "\n",
            "capulet:\n",
            "yourself fortenes his entmen\n",
            "this confinged our the tert a friar\n",
            "upon the men my\n",
            "---------1.0-----------\n",
            "ther, do so; set it on your head.\n",
            "\n",
            "montague:\n",
            "i must conceiner, daids strother was contreege,\n",
            "but i aw lopen the gow, as terchtazed at heart rais,\n",
            "who stouty to risay roold never a told resmen\n",
            "to 3 vilancy wall stay too chatten would the due.\n",
            "this aughmentory, lord's ploonhy were sortents;\n",
            "pout as is tenterly show.\n",
            "\n",
            "muchecis:\n",
            "if would thro\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}